{"title":"动漫电脑壁纸_爬虫","slug":"dongmanbizhi","date":"2018-09-15T03:23:55.000Z","updated":"2018-09-15T03:29:27.081Z","comments":true,"path":"api/articles/dongmanbizhi.json","photos":[],"link":"","excerpt":"无意中发现一个好网站，上面有很多美丽的动漫壁纸。图片太多，手动保存太慢，遂写此程序。<br>","covers":["/static/images/180.jpg"],"content":"<p>无意中发现一个好网站，上面有很多美丽的动漫壁纸。</p>\n<p>图片太多，手动保存太慢，遂写此程序。<br><a id=\"more\"></a>  </p>\n<p>源代码：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os <span class=\"comment\">#引入文件模块</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> re <span class=\"comment\">#正则表达式</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> urllib.request</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#连接网页并返回源码</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_url</span><span class=\"params\">(url)</span>:</span></span><br><span class=\"line\">      <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            req = urllib.request.Request(url)</span><br><span class=\"line\">            req.add_header(<span class=\"string\">\"User-Agent\"</span>, <span class=\"string\">\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36\"</span>)</span><br><span class=\"line\">            response = urllib.request.urlopen(req)</span><br><span class=\"line\">            <span class=\"comment\"># status_code = response.code</span></span><br><span class=\"line\">            html = response.read()</span><br><span class=\"line\">            <span class=\"keyword\">return</span> html</span><br><span class=\"line\">      <span class=\"keyword\">except</span>:</span><br><span class=\"line\">            print(url + <span class=\"string\">\" 404 网页丢失，请稍后再试!\"</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">404</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    dongman_url = <span class=\"string\">'https://www.dongmanxingkong.com/category/pic/wallpaper/page/1'</span></span><br><span class=\"line\">    dongman_url0 = <span class=\"string\">'https://www.dongmanxingkong.com/category/pic/wallpaper/page/'</span></span><br><span class=\"line\">    add_urls = [] <span class=\"comment\"># 网页列表</span></span><br><span class=\"line\">    paper_urls = [] <span class=\"comment\"># 壁纸地址列表</span></span><br><span class=\"line\">    img_num = <span class=\"number\">1</span> <span class=\"comment\"># 图片序列号</span></span><br><span class=\"line\">    os.chdir(<span class=\"string\">'PC_paper'</span>) <span class=\"comment\"># 转移到图片防止目录</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,<span class=\"number\">4</span>): <span class=\"comment\"># 搜集网页</span></span><br><span class=\"line\">        dongman_url = dongman_url0 + str(i)</span><br><span class=\"line\">        dongman_html = open_url(dongman_url)</span><br><span class=\"line\">        dongman_html = dongman_html.decode(<span class=\"string\">'utf-8'</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 正则表达式匹配</span></span><br><span class=\"line\">        add_url = re.findall(<span class=\"string\">r'class=\"post-title\"&gt;&lt;a href=\"([^\"]+\\.html)\" title=\"【电脑壁纸】'</span>,dongman_html)</span><br><span class=\"line\">        print(len(add_url))<span class=\"comment\"># 输出当前网页</span></span><br><span class=\"line\">        add_urls.extend(add_url) <span class=\"comment\"># 将子网页添加到列表中</span></span><br><span class=\"line\">    print(add_urls) <span class=\"comment\"># 输出列表</span></span><br><span class=\"line\">    print(len(add_urls)) <span class=\"comment\"># 列表长度</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> add_urls: <span class=\"comment\"># 从网页列表中搜集图片源地址</span></span><br><span class=\"line\">        print(i)</span><br><span class=\"line\"></span><br><span class=\"line\">        paper_html = open_url(i)</span><br><span class=\"line\">        paper_html = paper_html.decode(<span class=\"string\">'utf-8'</span>)</span><br><span class=\"line\">        paper_url = re.findall(<span class=\"string\">r'电脑壁纸 \" src=\"([^\"]+\\.jpg)\"'</span>,paper_html)</span><br><span class=\"line\">        paper_urls.extend(paper_url) <span class=\"comment\">#　将所有地址存放到列表中</span></span><br><span class=\"line\">        print(paper_url)</span><br><span class=\"line\"></span><br><span class=\"line\">    print(paper_urls)</span><br><span class=\"line\">    print(<span class=\"string\">'共'</span> + str(len(paper_urls)) + <span class=\"string\">'张,现在开始下载图片，请勿关闭程序!'</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 开始保存图片</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> paper_urls:</span><br><span class=\"line\">        file_name = str(img_num) + <span class=\"string\">'.jpg'</span></span><br><span class=\"line\">        img_html = open_url(i)</span><br><span class=\"line\">        <span class=\"keyword\">with</span> open(file_name, <span class=\"string\">'wb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            f.write(img_html)</span><br><span class=\"line\">        img_num = img_num + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"/static/images/180.jpg\" alt=\"bizhi\"></p>\n","categories":[{"name":"Python","slug":"Python","count":3,"path":"api/categories/Python.json"}],"tags":[{"name":"Python","slug":"Python","count":3,"path":"api/tags/Python.json"}]}